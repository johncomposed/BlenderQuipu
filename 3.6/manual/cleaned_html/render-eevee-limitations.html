<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml">
<head><title>Render &gt; Eevee &gt; Limitations</title></head>
<body><ul>
<li><a href="../index.html">Rendering</a></li>
<li><a href="index.html">Eevee</a></li>
<li>Limitations</li>
</ul><div>
<div itemprop="articleBody">
<section id="limitations">
<h1>Limitations</h1>
<p>Eevee’s goal is to be an interactive render engine. Some features may not be there yet or
may be impossible to implement into Eevee’s architecture without compromising performance.</p>
<p>Here is a rather exhaustive list of all the limitations you can expect while working with Eevee.</p>
<section id="cameras">
<h2>Cameras</h2>
<ul>
<li><p>Only perspective and orthographic projections are currently supported.</p></li>
</ul>
</section>
<section id="lights">
<h2>Lights</h2>
<ul>
<li><p>Only 128 active lights can be supported by Eevee in a scene.</p></li>
<li><p>Only 8 Shadowed sun lights can be supported at the same time.</p></li>
<li><p>As of now, lights can only have one color and do not support light node trees.</p></li>
</ul>
</section>
<section id="light-probes">
<h2>Light Probes</h2>
<ul>
<li><p>Eevee only supports up to 128 active Reflection Cubemaps.</p></li>
<li><p>Eevee only supports up to 64 active Irradiance Volumes.</p></li>
<li><p>Eevee only supports up to 16 active Reflection Planes inside the view frustum.</p></li>
</ul>
</section>
<section id="indirect-lighting">
<h2>Indirect Lighting</h2>
<ul>
<li><p>Volumetrics don’t receive light from Irradiance Volumes but do receive world’s diffuse lighting.</p></li>
<li><p>Eevee does not support “specular to diffuse” light bounces nor “specular to specular” light bounces.</p></li>
<li><p>All specular lighting is turned off during baking.</p></li>
</ul>
</section>
<section id="shadows">
<h2>Shadows</h2>
<ul>
<li><p>Only 128 active lights can be supported by Eevee in a scene.</p></li>
<li><p>Only 8 Shadowed sun lights can be supported at the same time.</p></li>
</ul>
</section>
<section id="volumetrics">
<h2>Volumetrics</h2>
<ul>
<li><p>Only single scattering is supported.</p></li>
<li><p>Volumetrics are rendered only for the camera “rays”. They don’t appear in reflections/refractions and probes.</p></li>
<li><p>Volumetrics don’t receive light from Irradiance Volumes but do receive diffuse lighting from the world.</p></li>
<li><p>Volumetric shadowing only work in volumetrics. They won’t cast shadows onto solid objects in the scene.</p></li>
<li><p>Volumetric shadowing only work for volumes inside the view frustum.</p></li>
<li><p>Volumetric lighting do not respect the lights shapes. They are treated as point lights.</p></li>
</ul>
</section>
<section id="depth-of-field">
<h2>Depth of Field</h2>
<ul>
<li><p>Alpha blended surfaces cannot be correctly handled by the post-processing blur,
but will be correctly handled by the sample-based method. For this, you need to
disable the post-process depth of field by setting the <em>Max Size</em> to 0.</p></li>
</ul>
</section>
<section id="screen-space-effects">
<h2>Screen Space Effects</h2>
<p>Eevee is not a ray tracing engine and cannot do ray-triangle intersection.
Instead of this, Eevee uses the depth buffer as an approximated scene representation.
This reduces the complexity of scene scale effects and enables a higher performance.
However, only what is in inside the view can be considered when computing these effects.
Also, since it only uses one layer of depth, only the front-most pixel distance is known.</p>
<p>These limitations creates a few problems:</p>
<ul>
<li><p>The screen space effects disappear when reaching the screen border.
This can be partially fixed by using the <em>overscan</em> feature.</p></li>
<li><p>Screen space effects lack deep information (or the thickness of objects).
This is why most effects have a thickness parameter to control how to consider potential intersected pixels.</p></li>
<li><p>Blended surfaces are not considered by these effects.
They are not part of the depth prepass and do not appear in the depth buffer.</p></li>
<li><p>Objects that a part of <a href="../layers/introduction.html#bpy-ops-outliner-collection-holdout-set">Holdout Collections</a>
will not be rendered with screen space effects.</p></li>
</ul>
<section id="ambient-occlusion">
<h3>Ambient Occlusion</h3>
<ul>
<li><p>Objects are treated as infinitely thick, producing overshadowing if the <em>Distance</em> is really large.</p></li>
</ul>
</section>
<section id="screen-space-reflections">
<h3>Screen Space Reflections</h3>
<ul>
<li><p>Only one glossy BSDF can emit screen space reflections.</p></li>
<li><p>The evaluated BSDF is currently arbitrarily chosen.</p></li>
<li><p>Screen Space Reflections will reflect transparent objects and objects using Screen Space Refraction
but without accurate positioning due to the one layer depth buffer.</p></li>
</ul>
</section>
<section id="screen-space-refraction">
<h3>Screen Space Refraction</h3>
<ul>
<li><p>Only one refraction event is correctly modeled.</p></li>
<li><p>Only opaque and alpha hashed materials can be refracted.</p></li>
</ul>
</section>
<section id="subsurface-scattering">
<h3>Subsurface Scattering</h3>
<ul>
<li><p>Only one BSSRDF can produce screen space subsurface scattering.</p></li>
<li><p>The evaluated BSSRDF is currently arbitrarily chosen.</p></li>
<li><p>A maximum of 254 different surfaces can use subsurface scattering.</p></li>
<li><p>Only scaling is adjustable per pixel. Individual RGB radii are adjustable in the socket default value.</p></li>
<li><p>Input radiance from each surfaces are not isolated during the blurring,
leading to light leaking from surface to surface.</p></li>
</ul>
</section>
</section>
<section id="motion-blur">
<h2>Motion Blur</h2>
<p><a href="render_settings/motion_blur.html">Motion Blur</a>
is only available in final renders and is not shown in the 3D Viewport
and thus <a href="../../editors/3dview/viewport_render.html#bpy-ops-render-opengl">Viewport Renders</a>.</p>
</section>
<section id="materials">
<h2>Materials</h2>
<dl>
<dt>Refractions</dt><dd><p>Refraction is faked by sampling the same reflection probe used by the Glossy BSDFs,
but using the refracted view direction instead of the reflected view direction.
Only the first refraction event is modeled correctly.
An approximation of the second refraction event can be used for relatively thin objects using Refraction Depth.
Using Screen Space refraction will refract what is visible inside the view,
and use the nearest probe if there is no hit.</p>
<p>Screen Space Reflections and Ambient Occlusion are not compatible with Screen Space Refraction;
they will be disabled on the surfaces that use it.
Surfaces that use Screen Space Refraction will not appear in Screen Space Reflections at the right place.
Surfaces that use Screen Space Refraction will not cast Ambient Occlusion onto other surfaces.</p>
</dd>
<dt>Volume Objects</dt><dd><p>Object volume shaders will affect the whole bounding box of the object.
The shape of the volume must be adjusted using procedural texturing inside the shader.</p>
</dd>
</dl>
</section>
<section id="shader-nodes">
<h2>Shader Nodes</h2>
<ul>
<li><p>All BSDF’s are using approximations to achieve realtime performance
so there will always be small differences between Cycles and Eevee.</p></li>
<li><p>Some utility nodes are not yet compatible with Eevee.</p></li>
</ul>
<div>
<p>See also</p>
<p>For a full list of unsupported nodes see <a href="materials/nodes_support.html">Nodes Support</a>.</p>
</div>
</section>
<section id="memory-management">
<h2>Memory Management</h2>
<p>In Eevee, <abbr title="Graphic Processing Unit, also known as Graphics Card">GPU</abbr>
Memory management is done by the GPU driver.
In theory, only the needed textures and meshes (now referred as “the resources”) for a single draw call
(i.e. one object) needs to fit into the GPU memory.</p>
<p>So if the scene is really heavy,
the driver will swap things in and out to make sure all objects are rendered correctly.</p>
<p>In practice, using too much GPU memory can make the GPU driver crash, freeze, or kill the application.
So be careful of what you ask.</p>
<p>There is no standard way of estimating if the resources will fit into the GPU memory and/or
if the GPU will render them successfully.</p>
</section>
<section id="cpu-rendering">
<h2>CPU Rendering</h2>
<p>Being a rasterization engine, Eevee only uses the power of
the <abbr title="Graphic Processing Unit, also known as Graphics Card">GPU</abbr> to render.
There is no plan to support <abbr title="Central Processing Unit">CPU</abbr> (software) rendering
as it would be very inefficient. CPU power is still needed to handle high scene complexity
as the geometry must be prepared by the CPU before rendering each frame.</p>
</section>
<section id="multiple-gpu-support">
<h2>Multiple GPU Support</h2>
<p>There is currently no support for
multiple <abbr title="Graphic Processing Unit, also known as Graphics Card">GPU</abbr> systems.</p>
</section>
<section id="headless-rendering">
<h2>Headless Rendering</h2>
<p>There is currently no support for using Eevee on headless systems (i.e. without a Display Manager).</p>
</section>
</section>
</div>
</div></body>
</html>